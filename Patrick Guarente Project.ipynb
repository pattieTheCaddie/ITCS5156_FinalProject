{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import requests as requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: How to get the data? ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1A: Working with Zillo API from RapidAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://zillow-working-api.p.rapidapi.com/byaddress\"\n",
    "\n",
    "querystring = {\"propertyaddress\":\"701 Royal Ct APT 304, Charlotte, NC 28202\"}\t#My condo address\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"e9cf3e65c2msh0de45007e2bea81p141686jsnc588f53da2b6\",\n",
    "\t\"X-RapidAPI-Host\": \"zillow-working-api.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1B: Working with HomeHarvest \n",
    "\n",
    "https://github.com/Bunsly/HomeHarvest?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install homeharvest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homeharvest import scrape_property\n",
    "from datetime import datetime\n",
    "\n",
    "# Loop through years from 2024 to 2004\n",
    "for year in range(2020, 2000, -1):\n",
    "    try:\n",
    "        \n",
    "        filename = f\"HomeHarvest_{year}_10_Miles_From_Home.csv\"\n",
    "        \n",
    "        # Set the date range for the current year\n",
    "        date_from = f\"{year}-01-01\"\n",
    "        date_to = f\"{year}-12-31\"\n",
    "        \n",
    "        # Call scrape_property for the current year\n",
    "        properties = scrape_property(\n",
    "            location=\"701 Royal Ct, Apt 304, Charlotte, NC\",\n",
    "            radius=10,\n",
    "            listing_type=\"sold\",\n",
    "            date_from=date_from,\n",
    "            date_to=date_to,\n",
    "            foreclosure=False\n",
    "        )\n",
    "        \n",
    "        # Check if properties were returned before attempting to save to a CSV\n",
    "        if len(properties) > 0:\n",
    "            print(f\"Number of properties for {year}: {len(properties)}\")\n",
    "            \n",
    "            # Save the properties to a CSV file\n",
    "            properties.to_csv(filename, index=False)\n",
    "            print(f\"Data saved to {filename}\")\n",
    "            print(properties.head())\n",
    "        else:\n",
    "            print(f\"No properties found for {year}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {year}: {e}. Skipping to the next year.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homeharvest import scrape_property\n",
    "from datetime import datetime\n",
    "\n",
    "current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"HomeHarvest_{current_timestamp}.csv\"\n",
    "#filename = \"HomeHarvest_2023_10_Miles_From_Home.csv\"\n",
    "\n",
    "properties = scrape_property(\n",
    "  location=\"701 Royal Ct,Apt 304,Charlotte,NC\",\n",
    "  #radius=10,\n",
    "  #location=\"Charlotte, NC\",  \n",
    "\n",
    "  listing_type=\"sold\",  # or (for_sale, for_rent, pending)\n",
    "  #past_days=10,  # sold in last 30 days - listed in last 30 days if (for_sale, for_rent)\n",
    "  \n",
    "  date_from=\"2022-01-01\", # alternative to past_days \n",
    "  date_to=\"2022-03-31\", \n",
    "  foreclosure=False\n",
    "  \n",
    "  # mls_only=True,  # only fetch MLS listings\n",
    ")\n",
    "print(f\"Number of properties: {len(properties)}\")\n",
    "\n",
    "properties.to_csv(filename, index=False)\n",
    "print(properties.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Pull data and start to play with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = \"HomeHarvest_2022_10_Miles_From_Home.csv\"    #Lets just work with 2020 data\n",
    "df_2020 = pd.read_csv(filename)\n",
    "#print(df_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(703, 6) (176, 6) (703,) (176,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pguarente\\AppData\\Local\\Temp\\ipykernel_3436\\2831059490.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_2020_Condos['half_baths'].fillna(0, inplace=True)    # set them all to 0 if they are null\n"
     ]
    }
   ],
   "source": [
    "#df_2020_Condos = df_2020[df_2020['style'] == 'PropertyType.CONDOS']\n",
    "df_2020_Condos = df_2020[df_2020['style'] == 'PropertyType.CONDOS']\n",
    "\n",
    "columns_to_drop = ['property_url', 'mls', 'mls_id', 'status', 'style', 'street', 'unit', 'city', 'state', 'zip_code',\n",
    "                   'list_date', 'list_price', 'lot_sqft', 'stories', 'hoa_fee', 'parking_garage', \n",
    "                   'primary_photo', 'alt_photos', 'last_sold_date', 'days_on_mls', 'price_per_sqft']\n",
    "\n",
    "df_2020_Condos = df_2020_Condos.drop(columns=columns_to_drop)\n",
    "\n",
    "# Half baths are put as null, we dont want to drop ALL of these\n",
    "df_2020_Condos['half_baths'].fillna(0, inplace=True)    # set them all to 0 if they are null\n",
    "df_2020_Condos['full_baths'] = df_2020_Condos['full_baths'] + 0.5 * df_2020_Condos['half_baths']        # Change the full baths to include the half baths\n",
    "\n",
    "# Drop the half baths because they are now accounted for in the full baths column\n",
    "df_2020_Condos.drop(columns=['half_baths'], inplace=True)\n",
    "\n",
    "df_2020_Condos = df_2020_Condos.dropna()\n",
    "\n",
    "#Define our data and target\n",
    "T = df_2020_Condos['sold_price']\n",
    "X = df_2020_Condos.drop(columns=['sold_price'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, T, test_size=0.2, random_state=27)\n",
    "\n",
    "print(X_train.shape, X_test.shape, t_train.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our SVC!\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "hyper_parameters = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'gamma': [1, 0.1, 0.01, 0.001], \n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(estimator=clf, param_grid=hyper_parameters)\n",
    "gscv.fit(X_train, t_train)\n",
    "best_params = gscv.best_params_\n",
    "\n",
    "print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.05689900426742532, Test Accuracy: 0.022727272727272728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, random_state=27)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train_scaled, t_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = clf.score(X_train_scaled, t_train)\n",
    "test_score = clf.score(X_test_scaled, t_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_score}, Test Accuracy: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.13320740194018443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming you have a regression model and predictions\n",
    "# For demonstration, let's say y_pred are your model's predictions, and y_test are the true values\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2_score_value = r2_score(t_test, y_pred)\n",
    "\n",
    "print(f\"R^2 Score: {r2_score_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sold Price: [440000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pguarente\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but SGDClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_condo = pd.read_csv(\"HomeHarvest_20240328_180841.csv\")\n",
    "df_condo = df_condo.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the half baths because they are now accounted for in the full baths column\n",
    "df_condo.drop(columns=['half_baths'], inplace=True)\n",
    "df_condo.drop(columns=['sold_price'], inplace=True)\n",
    "\n",
    "df_condo['full_baths'] = 1\n",
    "\n",
    "predicted_sold_price = clf.predict(df_condo)\n",
    "\n",
    "print(f\"Predicted Sold Price: {predicted_sold_price}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
